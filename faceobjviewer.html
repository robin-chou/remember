
<!DOCTYPE HTML>
<!--
	Alpha by HTML5 UP, modified by Joao F. Henriques
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild - Visual Geometry Group blog</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="//www.robots.ox.ac.uk/~vgg/blog/theme/css/main.css?version=1.2" />
		<!--[if lte IE 8]><link rel="stylesheet" href="//www.robots.ox.ac.uk/~vgg/blog/theme/css/ie8.css" /><![endif]-->
		<!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script> -->  <!-- maths, re-enable when needed -->
		<script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/jquery-3.4.1.min.js"></script>

		<!-- Open graph tags for customized share card on facebook and twitter -->
		<meta property="og:url" content="https://www.robots.ox.ac.uk/~vgg/blog/unsupervised-learning-of-probably-symmetric-deformable-3d-objects-from-images-in-the-wild.html" />
		<meta property="og:title" content="Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild - Visual Geometry Group blog" />
		<meta property="twitter:card" content="summary" />
		<meta property="twitter:title" content="Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild - Visual Geometry Group blog" />
		<meta property="og:description" content="We propose a method to learn weakly symmetric deformable 3D object categories from raw single-view images, without ground-truth 3D, multiple views, 2D/3D keypoints, prior shape models or any other supervision." />
		<meta property="twitter:description" content="We propose a method to learn weakly symmetric deformable 3D object categories from raw single-view images, without ground-truth 3D, multiple views, 2D/3D keypoints, prior shape models or any other supervision." />
		<meta property="og:image" content="https://www.robots.ox.ac.uk/~vgg/blog/images/unsup3d/preview_image.png" />
		<meta property="twitter:image" content="https://www.robots.ox.ac.uk/~vgg/blog/images/unsup3d/preview_image.png" />
	</head>
	<body class="landing ">
		<div id="page-wrapper">

			<!-- Header -->
				<!-- <header id="header" class="alt">
					<nav id="nav">
						<ul>
							<li><a href="index.html">Link</a></li>
						</ul>
					</nav>
				</header> -->

			<!-- Banner -->
				<section id="banner" class="">
					<h2><a href="//www.robots.ox.ac.uk/~vgg/blog/">Visual Geometry Group blog</a></h2>
					<p><a href="//www.robots.ox.ac.uk/~vgg/blog/">Research news from our lab at the University of Oxford</a></p>
				</section>

			<!-- Main -->
				<section id="main" class="container">

	<div class="box">
		<header class="major">
			<h2><a href="//www.robots.ox.ac.uk/~vgg/blog/unsupervised-learning-of-probably-symmetric-deformable-3d-objects-from-images-in-the-wild.html">Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild</a></h2>
			<h4>
<a href="//www.robots.ox.ac.uk/~vgg/blog/author/shangzhe-wu-christian-rupprecht-andrea-vedaldi.html">Shangzhe Wu & Christian Rupprecht & Andrea Vedaldi</a>			</h4>
		</header>

			<p><em>Summary: We propose a method to learn weakly symmetric deformable 3D object categories from raw single-view images, without ground-truth 3D, multiple views, 2D/3D keypoints, prior shape models or any other supervision.</em></p>

		<script>
$(document).ready(function () {
    initViewer();
    for (var i=1; i <= 15; i++)
        addDemoImageButton('human', i.zeroPad(3).toString() + '_face');
    for (var i=16; i <= 30; i++)
        addDemoImageButton('human', i.zeroPad(3).toString() + '_paint');
    for (var i=31; i <= 45; i++)
        addDemoImageButton('human', i.zeroPad(3).toString() + '_abstract');
    for (var i=1; i <= 23; i++)
        addDemoImageButton('cat', i.zeroPad(3).toString() + '_cat');
    for (var i=24; i <= 45; i++)
        addDemoImageButton('cat', i.zeroPad(3).toString() + '_abstract');
    render();
});
</script>

<style>
.faceselect {
    width: 100%;
    float: left;
    border: 1px solid black;
    margin: 0.5% 0.5% 0.5% 0;
    padding: 5px;
}

.faceselect.imgcontainer {
    width: 100%;
    display: flex;
    justify-content: space-between;
    flex-wrap: wrap;
}

.imgcontainer img {
    cursor: pointer;
    flex: 1 1 6.6%;
    width: 6.6%;
}

.lds-ellipsis {
  display: inline-block;
  position: relative;
  width: 80px;
  height: 80px;
}
.lds-ellipsis div {
  position: absolute;
  top: 33px;
  width: 13px;
  height: 13px;
  border-radius: 50%;
  background: #777;
  animation-timing-function: cubic-bezier(0, 1, 1, 0);
}
.lds-ellipsis div:nth-child(1) {
  left: 8px;
  animation: lds-ellipsis1 0.6s infinite;
}
.lds-ellipsis div:nth-child(2) {
  left: 8px;
  animation: lds-ellipsis2 0.6s infinite;
}
.lds-ellipsis div:nth-child(3) {
  left: 32px;
  animation: lds-ellipsis2 0.6s infinite;
}
.lds-ellipsis div:nth-child(4) {
  left: 56px;
  animation: lds-ellipsis3 0.6s infinite;
}
@keyframes lds-ellipsis1 {
  0% {
    transform: scale(0);
  }
  100% {
    transform: scale(1);
  }
}
@keyframes lds-ellipsis3 {
  0% {
    transform: scale(1);
  }
  100% {
    transform: scale(0);
  }
}
@keyframes lds-ellipsis2 {
  0% {
    transform: translate(0, 0);
  }
  100% {
    transform: translate(24px, 0);
  }
}

</style>

<p align="center" >
This work has received the <strong>CVPR 2020 Best Paper Award</strong>.
</p>

<p align="center">
  [<a href="https://arxiv.org/abs/1911.11130">Paper</a> &middot; <a href="https://elliottwu.com/projects/unsup3d/">Project Page</a> &middot; <a href="https://github.com/elliottwu/unsup3d">Code</a>]
</p>

<!-- more -->

<h2>Demo</h2>
<p><p class="image fit" style="max-width: 1024px">
    <div style="width:100%; display: flex">
        <div style="width: 10%; float: left; border: 1px solid black; margin: 5px 5px 5px 0; padding: 5px">
            <h4>Input</h4>
            <img alt="Input Image" id="inputimage" src="" style="max-width: 100%; display: none">
            <div id="loading_spinner" class="lds-ellipsis"><div></div><div></div><div></div><div></div></div>
        </div>
        <div style="width: 48%; float: left; border: 1px solid black; margin: 5px 5px 5px 0; padding: 5px">
            <h4>Upload your own image (&lt;1MB)</h4>
            <label for="face_type_input" style="display: inline-block; width: 5em">Face Type</label>
            <select id="face_type_input" style="display: inline-block; width: 6em; height: 2em; margin-right: 1em" onchange="faceTypeInputOnChange(this)">
              <option value="human">Human</option>
              <option value="cat">Cat</option>
            </select>
            <input type="checkbox" id="auto_crop_face_input" checked="" style="display: inline-block">
            <label for="auto_crop_face_input" id="auto_crop_face_input_label" style="display: inline-block">detect face region</label>
            <input type="file" id="local_file_uploader" onchange="local_file_uploader_onchange(this)" onclick="this.value=null" name="uploaded_local_file" accept="image/*">
            <h4 id="errormsg" style="color: red"></h4>
        </div>
        <div style="width: 30%; float: left; border: 1px solid black; margin: 5px 5px 5px 0; padding: 5px">
            <h4>Lighting Mode</h4>
            <input type="radio" id="rmNormal" name="rendermode" value="normal" onclick="changeRenderMode(this);">
            <label for="rmNormal">predicted</label>
            <input type="radio" id="rmRelighting" name="rendermode" value="relighting" onclick="changeRenderMode(this);">
            <label for="rmRelighting">relighting</label>
            <input type="radio" id="rmShading" name="rendermode" value="shading" onclick="changeRenderMode(this);">
            <label for="rmShading">geometry only</label>
        </div>
        <div style="width: 10%; float: left; border: 1px solid black; margin: 5px 5px 5px 0; padding: 5px">
            <h4>Share</h4>
            <a id="twitterlink" href="#" class="icon fa-twitter" style="font-size: 2.5em; line-height: 1.1;"><span class="label">Twitter</span></a>
            <a id="facebooklink" href="#" class="icon fa-facebook" style="font-size: 2.5em; line-height: 1.1;"><span class="label">Facebook</span></a>
        </div>
    </div>
    <p style="font-size: smaller; line-height: 1; color: #aaaaaa">We store a copy of the uploaded image for 7 days, after which it will be automatically deleted. The uploaded image is not used for any other purpose.</p>
    <div style="width: 100%; padding-top: 56.25%; position: relative;">
        <div id="faceViewerContainer" style="position: absolute; top: 0; bottom: 0; left: 0; right: 0;">
            <canvas id="faceViewerCanvas" style="width:100%; height: 100%; display: block"></canvas>
        </div>
    </div>
    <div class="faceselect" style="margin-bottom: 2em;">
        <h3>or select one of the examples below</h3>
        <div class="imgcontainer" id="demoimages"></div>
    </div>
</p></p>
<h2>Method Overview</h2>
<p>We propose a method to learn 3D deformable object categories
from raw single-view images, <strong>without any manual or external supervision</strong>.
The method is based on an autoencoder that factors
each input image into depth, albedo, viewpoint and illumination.
In order to disentangle these components without
supervision, we use the fact that many object categories have,
at least in principle, a symmetric structure. We show that reasoning
about illumination allows us to exploit the underlying
object symmetry even if the appearance is not symmetric due
to shading. Furthermore, we model objects that are probably,
but not certainly, symmetric by predicting a symmetry probability
map, learned end-to-end with the other components
of the model.</p>
<p class="image fit" style="max-width: 1024px">
  <iframe width="1024" height="576" src="https://www.youtube-nocookie.com/embed/5rPJyrU-WE4" style="max-width: 100%" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

<h3>Photo-Geometric Autoencoding</h3>
<p>Our method is based on an autoencoder that factors each input image into <strong>depth</strong>, <strong>albedo</strong>, <strong>viewpoint</strong> and <strong>lighting</strong>.
These four components are combined to reconstruct the input image. The model is trained only using a reconstruction loss, without any external supervision.</p>
<p class="image fit" style="max-width: 960px">
  <video autoplay loop muted inline width="960" style="max-width: 100%">
    <source src="./images/unsup3d/autoencoding.mp4" type="video/mp4" alt="Photo-Geometric Autoencoding">
  </video>
</p>

<h3>Exploiting Symmetry</h3>
<p>In order to achieve this decomposition without supervision, we exploit the fact that many object categories have <strong>a bilateral symmetry</strong>.
Assuming an object is perfectly symmetric, one can obtain a virtual second view of it by simply mirroring the image and perform 3D reconstruction using stereo geometry [1, 2].</p>
<p>Here, we would like to leverage this symmetry assumption.
We enforce the model to predict a symmetric view of the object by injecting a flipping operation, and obtain two reconstructions (with and without flipping) of the same input view through predicted viewpoint transformation.
Minimizing two reconstruction losses at the same time essentially imposes a &ldquo;two-view&rdquo; constraint and provides sufficient signal for recovering accurate 3D shapes.</p>
<p class="image fit" style="max-width: 960px">
  <video autoplay loop muted inline width="960" style="max-width: 100%">
    <source src="./images/unsup3d/symmetry.mp4" type="video/mp4" alt="Exploiting symmetry via Photo-Geometric Autoencoding">
  </video>
</p>

<p>Note that even if an object has symmetric intrinsic textures (aka. albedo), it may still result in an asymmetric appearance due to asymmetric illumination.
Here, this is handled by predicting albedo and lighting separately, and enforcing symmetry only on albedo while allowing the shading to be asymmetric.
We assume a simple Lambertian illumination model, and compute a shading map from the predicted light direction and depth map.</p>
<p>In fact, doing so does not only allow the model to learn accurate intrinsic image decomposition, but also provides strong regularization on the shape prediction (similar to shape from shading)!
Unnatural shapes are avoided since they result in unnatural shading and thus a higher reconstruction loss.</p>
<h3>Probabilistic Modeling of Symmetry using Confidence Maps</h3>
<p>Although symmetry provides strong signal for recovering 3D shapes, specific object instances are in practice never fully symmetric.
We account for potential asymmetry using uncertainty modeling [3].
Our model additionally predicts a pair of per-pixel confidence maps, and is trained to minimize the two confidence-adjusted reconstruction losses at the same time, and with asymmetric weights to allow for a dominant side.</p>
<p class="image fit" style="max-width: 960px">
  <video autoplay loop muted inline width="960" style="max-width: 100%">
    <source src="./images/unsup3d/confidence.mp4" type="video/mp4" alt="Probabilistic modeling of symmetry using confidence maps">
  </video>
</p>

<h3>Acknowledgements</h3>
<p>We are deeply indebted to all members of Visual Geometry Group for insightful discussions and suggestions, in particular, Sophia Koepke, Gül Varol, Erika Lu, Olivia Wiles, Iro Laina, Dan Xu, Fatma Güney, Tengda Han and Andrew Zisserman. We would also like to thank Abhishek Dutta, Ernesto Coto and João Henriques for their assistance in setting up this demo website. We are also grateful to Soumyadip Sengupta for sharing with us the code to generate synthetic face datasets, and to Mihir Sahasrabudhe for sending us the reconstruction results of Lifting AutoEncoders. This work is jointly supported by Facebook Research and ERC Horizon 2020 research and innovation programme IDIU 638009.</p>
<h3>References</h3>
<p><br>
[1] Mirror Symmetry ⇒ 2-View Stereo Geometry. Alexandre R. J. François, Gérard G. Medioni, and Roman Waupotitsch. Image and Vision Computing, 2003.
<br>
[2] Detecting and Reconstructing 3D Mirror Symmetric Objects. Sudipta N. Sinha, Krishnan Ramnath, and Richard Szeliski. Proc. ECCV, 2012.
<br>
[3] What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? Alex Kendall and Yarin Gal. NeurIPS, 2017.
<br></p>
<p>Author&rsquo;s webpage: <a href="https://elliottwu.com/">Shangzhe</a> &amp; <a href="https://chrirupp.github.io/">Christian</a></p>

		<h5 class="align-right header" style="font-style: italic">
<a href="//www.robots.ox.ac.uk/~vgg/blog/author/shangzhe-wu-christian-rupprecht-andrea-vedaldi.html">Shangzhe Wu & Christian Rupprecht & Andrea Vedaldi</a>, 26 February 2020
		</h5>

		<ul class="icons align-right">
			<li><a href="https://twitter.com/share?url=https://www.robots.ox.ac.uk/~vgg/blog/unsupervised-learning-of-probably-symmetric-deformable-3d-objects-from-images-in-the-wild.html" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
			<li><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.robots.ox.ac.uk/~vgg/blog/unsupervised-learning-of-probably-symmetric-deformable-3d-objects-from-images-in-the-wild.html" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
		</ul>

	</div>

	<h2 class="align-center">More from the VGG blog</h2>

	<div class="row">
		<div class="3u 4u(narrow) 6u(mobilep)">

			<section class="box special">
				<a href="//www.robots.ox.ac.uk/~vgg/blog/shapestacks-giving-robots-a-physical-intuition.html"><span class="image featured"><img src="//www.robots.ox.ac.uk/~vgg/blog/images/shapestacks/shapestacks_thumbnail.png" alt="" /></span>
				<h3>ShapeStacks: Giving Robots a Physical Intuition</h3></a>
			</section>

		</div>
		<div class="3u 4u(narrow) 6u(mobilep)">

			<section class="box special">
				<a href="//www.robots.ox.ac.uk/~vgg/blog/self-labelling-via-simultaneous-clustering-and-representation-learning.html"><span class="image featured"><img src="//www.robots.ox.ac.uk/~vgg/blog/images/selflabel/overview.png" alt="" /></span>
				<h3>Self-Labelling via simultaneous clustering and representation learning</h3></a>
			</section>

		</div>
		<div class="3u 4u(narrow) 6u(mobilep)">

			<section class="box special">
				<a href="//www.robots.ox.ac.uk/~vgg/blog/mapping-environments-with-deep-networks.html"><span class="image featured"><img src="//www.robots.ox.ac.uk/~vgg/blog/images/mapnet/pointcloud.png" alt="" /></span>
				<h3>Mapping environments with deep networks</h3></a>
			</section>

		</div>
		<div class="3u 4u(narrow) 6u(mobilep)">

			<section class="box special">
				<a href="//www.robots.ox.ac.uk/~vgg/blog/comparator-networks.html"><span class="image featured"><img src="//www.robots.ox.ac.uk/~vgg/blog/images/comparator/thumbnail.png" alt="" /></span>
				<h3>Comparator Networks</h3></a>
			</section>

		</div>
	</div>

				</section>

			<!-- CTA --> <!-- alternative: https://web.maillist.ox.ac.uk/ox/subscribe/vggblog/<email> -->
				<!--
				<section id="cta">

					<h2>Receive new posts by e-mail</h2>
					<p>At most one post per week.</p>

					<form action="https://web.maillist.ox.ac.uk/ox/" method="POST">
						<input type="hidden" name="action" value="subscribe" />
						<input type="hidden" name="list" value="vggblog" />
						<div class="row uniform 50%">
							<div class="8u 12u(mobilep)">
								<input name="email" id="email" placeholder="Email Address" type="email">
							</div>
							<div class="4u 12u(mobilep)">
								<input value="Sign Up" class="fit" type="submit">
							</div>
						</div>
					</form>

				</section>
				-->

			<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
 <li><a href="//www.robots.ox.ac.uk/~vgg/blog/" class="icon fa-chevron-circle-left"><span class="label">VGG blog</span></a></li> 						<li><a href="http://www.robots.ox.ac.uk/~vgg/" class="icon fa-home"><span class="label">VGG website</span></a></li>
						<li><a href="//www.robots.ox.ac.uk/~vgg/blog/feeds/all.atom.xml" class="icon fa-rss"><span class="label">RSS feed</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Visual Geometry Group.</li>
						<li>Reuse permitted under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a> license.</li>
						<li>Design by <a href="http://html5up.net">HTML5 UP</a>, adapted by <a href="http://www.robots.ox.ac.uk/~joao/">Jo&atilde;o F. Henriques</a></li>
						<li><a style="background-color:none;color:999;text-decoration:none;border-bottom:none;padding:4px 6px;line-height:1.2;display:inline-block;border-radius:3px;" href="https://unsplash.com/@nandreev?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Nikita Andreev"><span style="display:inline-block;padding:2px 3px;"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-1px;fill:#909090;" viewBox="0 0 32 32"><title>unsplash-logo</title><path d="M20.8 18.1c0 2.7-2.2 4.8-4.8 4.8s-4.8-2.1-4.8-4.8c0-2.7 2.2-4.8 4.8-4.8 2.7.1 4.8 2.2 4.8 4.8zm11.2-7.4v14.9c0 2.3-1.9 4.3-4.3 4.3h-23.4c-2.4 0-4.3-1.9-4.3-4.3v-15c0-2.3 1.9-4.3 4.3-4.3h3.7l.8-2.3c.4-1.1 1.7-2 2.9-2h8.6c1.2 0 2.5.9 2.9 2l.8 2.4h3.7c2.4 0 4.3 1.9 4.3 4.3zm-8.6 7.5c0-4.1-3.3-7.5-7.5-7.5-4.1 0-7.5 3.4-7.5 7.5s3.3 7.5 7.5 7.5c4.2-.1 7.5-3.4 7.5-7.5z"></path></svg></span><span style="display:inline-block;padding:2px 3px;">Nikita Andreev</span></a></li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
			<!-- <script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/jquery.dropotron.min.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/jquery.scrollgress.min.js"></script> -->
			<script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/skel.min.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/util.js"></script>
			<!--[if lte IE 8]><script src="theme/js/ie/respond.min.js"></script><![endif]-->
			<script src="//www.robots.ox.ac.uk/~vgg/blog/theme/js/main.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/Chart.bundle.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/chartjs-plugin-deferred.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/three.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/OrbitControls.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/OBJLoader.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/MTLLoader.js"></script>
			<script src="//www.robots.ox.ac.uk/~vgg/blog/js/unsup3d.js"></script>

            <script>  //open external links in a new tab/window
            $(document.links).filter(function() {
                return this.hostname != window.location.hostname;
            }).attr('target', '_blank');
            </script>

	</body>
</html>
